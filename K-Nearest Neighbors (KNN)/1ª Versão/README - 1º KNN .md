# M√©todo k-NN (k-Nearest Neighbors) de IA

Fiz este algoritmo como parte de uma atividade do meu primeiro semestre na UEL, para a mat√©ria de Introdu√ß√£o √† Ci√™ncia de Dados e IA ü§ñüë®‚Äçüíª

## Descri√ß√£o do k-NN

O m√©todo KNN √© modelo de machine learning utilizado para classsificar amostras novas com uma base pr√©via de dados de treinamento. Seu funcionamento consiste no c√°lculo da dist√¢ncia dos dados de treinamento em rela√ß√£o ao dado a ser classificado; depois s√£o selecionados os k vizinhos mais pr√≥ximos (sendo k um n√∫mero inteiro maior que 0) e √© contado a quantidade de cada classe deles; ao final, o r√≥tulo mais frequente dentre os vizinhos √© atribu√≠do ao dado que est√° sendo classificado.

### _Fun√ß√£o knn()_

!! _*Aviso inicial*_ !! : as amostras n√£o devem ser do formato de dataframe (n√£o funciona com o Pandas). Deve-se colocar o nome do arquivo + .csv entre aspas. Ou tamb√©m pode atribuir essa nomenclatura a vari√°veis para servirem de entrada.

```
# Exemplo de como chamar a fun√ß√£o

knn(3, "Aula 18 - dataset_alterado_2.csv", "teste_2.csv")
```

1. Recebe o valor k (n√∫mero de vizinhos pr√≥ximos a serem considerados), a amostra*treino (vari√°vel \*\*\_df_treino***), a amostra_teste (vari√°vel **_df_teste_**), e um valor para a vari√°vel **_cabecalho_\*\* que pode compartar os seguintes valores:

```
Cabecalho == 0: N√£o tem em nenhuma das amostras
Cabecalho == 1: Tem na df_treino
Cabecalho == 2: Tem na df_teste
Cabecalho == 3: Tem nos dois (valor padr√£o).
```

2. Dentro da fun√ß√£o, s√£o abertos os dois arquivos csv e √© identificado se o que foi passado no par√¢metro est√° correto, se n√£o tiver o c√≥digo n√£o funcionar√° ou imprimir√° uma mensagem de erro.

3. √â feito a formata√ß√£o as duas amostras para preencher as lacunas vazias com o n√∫mero 0 e para transform√°-las em matrizes bidimensionais.

4. √â feito o c√°lculo da dist√¢ncia euclidiana de todas as linhas do **_df_treino_** em rela√ß√£o a primeira linha de **_df_teste_**, e s√£o armazenadas na v√°riavel **_valores_**.

5. Utiliza-se na vari√°vel **_valores_** a fun√ß√£o sort para ordena-l√° de forma ascendente. Ainda com **_valores_** , √© coletado a quantidade k dos valores mais pr√≥ximos (em rela√ß√£o a linha da amostra teste que est√° sendo iterada) e s√£o armazenados na vari√°vel **_neighbors_**.

6. Conta-se a quantidade de cada r√≥tulo que aparece na vari√°vel **_neighbors_**, a qual s√£o registradas na vari√°vel **_list_label_**.

7. Se a frequ√™ncia de um r√≥tulo for maior que a do outro, ele √© atribu√≠do √† uma lista chamada **_labels_**, o qual det√©m os r√≥tulos encontrados pela fun√ß√£o k-nn. Se houver um empate, ent√£o √© adicionado o r√≥tulo do vizinho mais pr√≥ximo (menor dist√¢ncia euclidiana).

8. O mesmo processo √© realizado para as demais linhas de **_df_teste_** e, por fim, √© retornado para a fun√ß√£o main() a vari√°vel **_labels_**, que cont√©m as classes encontradas pela fun√ß√£o.

## Outros Detalhes

. _Crit√©rio de desempate_: voto do vizinho mais pr√≥ximo

. _M√©trica de dist√¢ncia_: euclidiana

. _Bibliotecas de python utilizadas_: nenhuma

. _Porcentagem da amostra treino_: 80%

. _Porcentagem da amostra teste_: 20%

. _√öltima informa√ß√£o_: o n√∫mero de colunas entre as amostras tem que ser o mesmo, por√©m o conjunto de dados de onde foram tiradas pode ter qualquer quantidade de atributos.
